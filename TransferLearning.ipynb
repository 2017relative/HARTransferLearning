{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf-8\n",
    "\n",
    "import data_preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import transferlearningnetwork as net\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import tqdm\n",
    "import maximum_mean_discrepancy\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCH = 10\n",
    "lr = 0.01\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "result = []\n",
    "LAMBDA = 0.25\n",
    "l2_decay = 5e-4\n",
    "momentum = 0.9\n",
    "GAMMA = 10 ^ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmd_loss(x_src, x_tar):\n",
    "    return maximum_mean_discrepancy.mmd_rbf_noaccelerate(x_src, x_tar)\n",
    "\n",
    "def train(model, source_loader, target_loader):\n",
    "    \n",
    "    n_batch = len(source_loader.dataset) // BATCH_SIZE\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    iter_target = iter(target_loader)\n",
    "    len_target_loader = len(target_loader)\n",
    "    for e in range(N_EPOCH):\n",
    "        LEARNING_RATE = lr / math.pow((1 + 10 * e / N_EPOCH), 0.75)\n",
    "        optimizer = optim.SGD(params=model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=l2_decay)\n",
    "        \n",
    "        model.train()\n",
    "        correct, total_loss = 0, 0\n",
    "        total = 0\n",
    "        \n",
    "        for index, (sample, target) in enumerate(source_loader):\n",
    "            \n",
    "            data_target, label_target = iter_target.next()\n",
    "            if index % (len_target_loader-1) == 0:\n",
    "                iter_target = iter(target_loader)\n",
    "            \n",
    "            sample, target = sample.to(DEVICE).float(), target.to(DEVICE).long()\n",
    "            sample = sample.view(-1, 3, 1, 200)\n",
    "            data_target, label_target = data_target.to(DEVICE).float(), label_target.to(DEVICE).long()\n",
    "            data_target = data_target.view(-1, 3, 1, 200)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_src, x_src_mmd, x_tar_mmd = model(sample, data_target)\n",
    "            loss_c = criterion(y_src, target)\n",
    "            loss_mmd = mmd_loss(x_src_mmd, x_tar_mmd)\n",
    "            _, predicted = torch.max(y_src.data, 1)\n",
    "            correct += (predicted == target).sum()\n",
    "            \n",
    "            loss_cls = F.nll_loss(F.log_softmax(y_src, dim=1), target)\n",
    "            gamma = 2 / (1 + math.exp(-10 * (e) / N_EPOCH)) - 1\n",
    "            loss = loss_cls + gamma * loss_mmd\n",
    "            #loss = loss_c + LAMBDA * loss_mmd\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data\n",
    "            total += target.size(0)\n",
    "            \n",
    "            if index % 20 == 0:\n",
    "                tqdm.tqdm.write('Epoch: [{}/{}], Batch: [{}/{}], loss:{:.4f}'.format(e + 1, N_EPOCH, index + 1, n_batch, loss.data))\n",
    "\n",
    "    acc_train = float(correct) * 100.0 / (BATCH_SIZE * n_batch)\n",
    "    tqdm.tqdm.write('Epoch: [{}/{}], Total loss: {:.4f}, train acc: {:.2f}%'.format(e + 1, N_EPOCH, total_loss * 1.0 / n_batch, acc_train))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, target_loader):\n",
    "    total_loss_test = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for index, (sample, target) in enumerate(target_loader):\n",
    "            sample, target = sample.to(DEVICE).float(), target.to(DEVICE).long()\n",
    "            sample = sample.view(-1, 3, 1, 200)\n",
    "            output, _, _  = model(sample, sample)\n",
    "            loss = criterion(output, target)\n",
    "            #print('loss : ', loss)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_loss_test += loss.data\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum()\n",
    "            \n",
    "    acc_test = float(correct) * 100 / total\n",
    "    tqdm.tqdm.write('Test: loss: {:.6f}, correct: [{}/{}], test acc: {:.4f}%'.format(loss, correct, total, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jogging', 'Sit_Down', 'Skip', 'Stand_Up', 'Stay', 'Walk']\n",
      "Hasc_X_train.shape :  (9832, 3, 1, 200)\n",
      "Hasc_Y_train.shape :  (9832,)\n",
      "Hasc_Y_train values :  [0 0 0 ... 1 1 1]\n",
      "Wisdm_X_train.shape :  (38319, 3, 1, 200)\n",
      "Wisdm_Y_train shape :  (38319,)\n",
      "Wisdm_Y_train values :  [0 0 0 ... 1 1 1]\n",
      "Epoch: [1/10], Batch: [1/153], loss:0.6943\n",
      "Epoch: [1/10], Batch: [21/153], loss:0.6228\n",
      "Epoch: [1/10], Batch: [41/153], loss:0.5109\n",
      "Epoch: [1/10], Batch: [61/153], loss:0.3008\n",
      "Epoch: [1/10], Batch: [81/153], loss:0.2106\n",
      "Epoch: [1/10], Batch: [101/153], loss:0.2374\n",
      "Epoch: [1/10], Batch: [121/153], loss:0.0740\n",
      "Epoch: [1/10], Batch: [141/153], loss:0.0484\n",
      "Epoch: [2/10], Batch: [1/153], loss:1.2106\n",
      "Epoch: [2/10], Batch: [21/153], loss:0.7577\n",
      "Epoch: [2/10], Batch: [41/153], loss:0.7529\n",
      "Epoch: [2/10], Batch: [61/153], loss:0.7154\n",
      "Epoch: [2/10], Batch: [81/153], loss:0.7305\n",
      "Epoch: [2/10], Batch: [101/153], loss:0.7176\n",
      "Epoch: [2/10], Batch: [121/153], loss:0.6555\n",
      "Epoch: [2/10], Batch: [141/153], loss:0.6828\n",
      "Epoch: [3/10], Batch: [1/153], loss:0.7123\n",
      "Epoch: [3/10], Batch: [21/153], loss:0.5851\n",
      "Epoch: [3/10], Batch: [41/153], loss:0.5180\n",
      "Epoch: [3/10], Batch: [61/153], loss:0.5338\n",
      "Epoch: [3/10], Batch: [81/153], loss:0.4406\n",
      "Epoch: [3/10], Batch: [101/153], loss:0.7604\n",
      "Epoch: [3/10], Batch: [121/153], loss:0.4563\n",
      "Epoch: [3/10], Batch: [141/153], loss:0.4442\n",
      "Epoch: [4/10], Batch: [1/153], loss:0.8433\n",
      "Epoch: [4/10], Batch: [21/153], loss:0.5258\n",
      "Epoch: [4/10], Batch: [41/153], loss:0.6151\n",
      "Epoch: [4/10], Batch: [61/153], loss:0.8773\n",
      "Epoch: [4/10], Batch: [81/153], loss:0.3586\n",
      "Epoch: [4/10], Batch: [101/153], loss:0.3491\n",
      "Epoch: [4/10], Batch: [121/153], loss:0.4884\n",
      "Epoch: [4/10], Batch: [141/153], loss:0.5055\n",
      "Epoch: [5/10], Batch: [1/153], loss:0.6186\n",
      "Epoch: [5/10], Batch: [21/153], loss:0.2908\n",
      "Epoch: [5/10], Batch: [41/153], loss:0.3338\n",
      "Epoch: [5/10], Batch: [61/153], loss:0.2537\n",
      "Epoch: [5/10], Batch: [81/153], loss:0.2406\n",
      "Epoch: [5/10], Batch: [101/153], loss:0.2745\n",
      "Epoch: [5/10], Batch: [121/153], loss:0.2342\n",
      "Epoch: [5/10], Batch: [141/153], loss:0.2685\n",
      "Epoch: [6/10], Batch: [1/153], loss:0.5330\n",
      "Epoch: [6/10], Batch: [21/153], loss:0.2454\n",
      "Epoch: [6/10], Batch: [41/153], loss:0.3652\n",
      "Epoch: [6/10], Batch: [61/153], loss:0.2586\n",
      "Epoch: [6/10], Batch: [81/153], loss:0.2301\n",
      "Epoch: [6/10], Batch: [101/153], loss:0.2486\n",
      "Epoch: [6/10], Batch: [121/153], loss:0.2362\n",
      "Epoch: [6/10], Batch: [141/153], loss:0.2633\n",
      "Epoch: [7/10], Batch: [1/153], loss:0.4261\n",
      "Epoch: [7/10], Batch: [21/153], loss:0.1547\n",
      "Epoch: [7/10], Batch: [41/153], loss:0.2012\n",
      "Epoch: [7/10], Batch: [61/153], loss:0.2494\n",
      "Epoch: [7/10], Batch: [81/153], loss:0.2251\n",
      "Epoch: [7/10], Batch: [101/153], loss:0.2975\n",
      "Epoch: [7/10], Batch: [121/153], loss:0.2400\n",
      "Epoch: [7/10], Batch: [141/153], loss:0.2519\n",
      "Epoch: [8/10], Batch: [1/153], loss:0.4073\n",
      "Epoch: [8/10], Batch: [21/153], loss:0.1908\n",
      "Epoch: [8/10], Batch: [41/153], loss:0.1933\n",
      "Epoch: [8/10], Batch: [61/153], loss:0.2376\n",
      "Epoch: [8/10], Batch: [81/153], loss:0.2546\n",
      "Epoch: [8/10], Batch: [101/153], loss:0.2789\n",
      "Epoch: [8/10], Batch: [121/153], loss:0.2315\n",
      "Epoch: [8/10], Batch: [141/153], loss:0.2063\n",
      "Epoch: [9/10], Batch: [1/153], loss:0.2648\n",
      "Epoch: [9/10], Batch: [21/153], loss:0.1894\n",
      "Epoch: [9/10], Batch: [41/153], loss:0.1772\n",
      "Epoch: [9/10], Batch: [61/153], loss:0.1927\n",
      "Epoch: [9/10], Batch: [81/153], loss:0.2295\n",
      "Epoch: [9/10], Batch: [101/153], loss:0.3270\n",
      "Epoch: [9/10], Batch: [121/153], loss:0.2239\n",
      "Epoch: [9/10], Batch: [141/153], loss:0.2097\n",
      "Epoch: [10/10], Batch: [1/153], loss:0.3210\n",
      "Epoch: [10/10], Batch: [21/153], loss:0.1549\n",
      "Epoch: [10/10], Batch: [41/153], loss:0.2116\n",
      "Epoch: [10/10], Batch: [61/153], loss:0.1998\n",
      "Epoch: [10/10], Batch: [81/153], loss:0.2141\n",
      "Epoch: [10/10], Batch: [101/153], loss:0.2042\n",
      "Epoch: [10/10], Batch: [121/153], loss:0.1957\n",
      "Epoch: [10/10], Batch: [141/153], loss:0.2044\n",
      "Epoch: [10/10], Total loss: 0.2048, train acc: 98.21%\n",
      "['Jogging', 'Sit_Down', 'Skip', 'Stand_Up', 'Stay', 'Walk']\n",
      "Hasc_X_train.shape :  (9832, 3, 1, 200)\n",
      "Hasc_Y_train.shape :  (9832,)\n",
      "Hasc_Y_train values :  [0 0 0 ... 1 1 1]\n",
      "Wisdm_X_train.shape :  (38319, 3, 1, 200)\n",
      "Wisdm_Y_train shape :  (38319,)\n",
      "Wisdm_Y_train values :  [0 0 0 ... 1 1 1]\n",
      "Test: loss: 0.545393, correct: [21610/38319], test acc: 56.3950%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(10)\n",
    "    source_loader, target_loader = data_preprocess.load(batch_size=BATCH_SIZE)\n",
    "    model = net.Network().to(DEVICE)\n",
    "    model = train(model, source_loader, target_loader)\n",
    "    dummysource_loader, test_loader = data_preprocess.load(batch_size=BATCH_SIZE)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
